\documentclass[12pt,a4paper,reqno]{amsart}
\usepackage{amssymb}
\usepackage{mathbbol}
\usepackage[latin2]{inputenc}
\usepackage{t1enc}
\usepackage[margin=2.9cm]{geometry}

\theoremstyle{plain}
% \newtheorem{Th}{Theorem}[section]
\newtheorem{Th}{Theorem}
\newtheorem{Lemma}[Th]{Lemma}
\newtheorem{Cor}[Th]{Corollary}
\newtheorem{Prop}[Th]{Proposition}

\theoremstyle{definition}
\newtheorem{Def}[Th]{Definition}
\newtheorem{Conj}[Th]{Conjecture}
\newtheorem{Rem}[Th]{Remark}
\newtheorem{?}[Th]{Problem}
\newtheorem{Ex}[Th]{Example}


\begin{document}

\title{Unusual proofs of some elemental inequalities}


\author{Jimin Shi}

\address{Shanxi Normail University \\ Department of Mathematics \\
\\ Linfen, Shanxi 041000 \\ P. R. China} 

\email{jimin.shi@foxmail.com}


% \subjclass[2010]{Primary: 05C??. Secondary: 05C??}



% \keywords{sample paper} 



\begin{abstract} This paper provides the unusual proofs of some elemental inequalities, including the basic one, H\"older's, Jensen's and so on, and shows the use of Bernoulli's and Calculus method.
\end{abstract}

\maketitle

\section{Introduction} 
This article intends to start from a comparative perspective and use analysis tools to give different kinds of proofs to elementary inequalities for reference.

The vector in the article, if not specifically stated, always assumes that its components are all positive numbers and are represented in bold letters. And the bold letter function represents such a vector: Its components are calculated according to the algorithm indicated by the function formula. E.g.: 

$\mathbb{a}=\left( \begin{array}{c} a_1 \\ \vdots \\ a_n \end{array} \right)$, 
$\mathbb{a} + \mathbb{b} = \left( \begin{array}{c} a_1 + b_1 \\ \vdots \\ a_n + b_n \end{array} \right)$,
$\mathbb{a} \cdot \mathbb{b} = \left( \begin{array}{c} a_1 b_1 \\ \vdots \\ a_n b_n \end{array} \right)$, 
$\mathbb{a}^{\alpha} \mathbb{b}^{1-\alpha} = \left( \begin{array}{c} a_1^{\alpha} b_1^{1-\alpha} \\ \vdots \\ a_n^{\alpha} b_n^{1-\alpha} \end{array} \right)$, 
$f(a)=\left( \begin{array}{c} f(a_1) \\ \vdots \\ f(a_n) \end{array} \right)$, etc. 

The frequently used symbols are:

$|\mathbb{a}| = |\mathbb{a}|_1 \triangleq \sum{a_i}$, $|\mathbb{c}\cdot \mathbb{a}^r|^{\frac{1}{r}}  \triangleq \left( \sum{c_i a_i^r}\right)^{\frac{1}{r}}$

especially, when $c_i \equiv 1$, $|\mathbb{a}|_r = |\mathbb{a}^r|^{\frac{1}{r}} = \left( \sum{a_i^r}\right)^{\frac{1}{r}}$

when $c_i > 0 ~\& \sum{c_i} = 1$, $|\mathbb{c}\cdot \mathbb{a}^r|^{\frac{1}{r}}\triangleq M(r_j;\mathbb{a}, \mathbb{c}) \triangleq (\sum_{i}^{n}c_i a_i^r)^{\frac{1}{r}}$ 


\section{Basic inequality}

Inequalities that occupy a special important position in inequality systems $A\geqslant G$, There is no lack of exquisite proofs~\cite{shi1964}. The analysis presented here proves that it is worth learning from the paradigm of the application of analytical methods. 


\begin{Th} \label{th1} 

\begin{equation}
  \frac{a_1 + \cdots +a_n}{n} \triangleq A \geqslant G \triangleq \geqslant (a_1 \cdots a_n)^{\frac{1}{n}}
\end{equation}

\end{Th}

\begin{proof} First, from $(a_1 - a_2)^2$ one can see Eq.\eqref{th1} is established when $n=2$. 
  Then, let Eq.\eqref{th1} true when $n=k$, proof true when $n=k+1$. 
  
  Note  
  $$A_k = \frac{a_1+\cdots+a_k}{k}, G_k = (a_1\cdots a_k)^{\frac{1}{k}}$$ 
  $$A_{k+1} = \frac{a_1+\cdots+a_k+x}{k+1} = \frac{kA_k+x}{k+1}$$ 
  $$ G_{k+1}=(a_1\cdots a_k\cdot x)^{\frac{1}{k+1}} = (G_k^k \cdot x)^{\frac{1}{k+1}}$$
  where x is any positive number. 

Let  $$f(x)\triangleq \ln \frac{G_{k+1}}{A_{k+1}} $$
then $$f^{\prime}(x)=\frac{1}{k+1}\cdot\frac{1}{x} - \frac{1}{k\cdot A_k+x}$$
$$ f^{\prime\prime}(x) = \frac{-1}{(k+1)\cdot x^2} + \frac{1}{(k\cdot+x)^2} $$
and  $f^{\prime}(x) = 0 $ root $x_0 = A_k$. 

Because $$ f^{\prime\prime}(x_0) = \frac{1-(k+1)}{(k+1)^2\cdot A_k} < 0 $$
Then one know this function defined on $(0, \infty)$ with better smoothness (i.e. has no singularity other than stationary point $x_0$ reaches the maximum at $x_0$ (upward convex). which is: 

$$
\max[x\in (0, \infty)] f(x) = f(x_0) = \frac{k}{k+1}\cdot \ln \frac{G_k}{A_k} \leqslant 0. 
$$

where the $\leqslant$ used introduction hypothesis, that is $A_{k+1} \leqslant G_{k+1}$. 
\end{proof}

Note: Since the average of rational numbers can be averaged as uniform weighted average, the average of irrational number weights can be approximated by the sequence of rational number weights, and the inequality relationship $\geqslant$ and $\leqslant$ remains unchanged during the limit. Therefore, an inequality that is related to the average value is established for any weight if it is established for the weighted average. In other words, if it is established by \eqref{th1}, the following formula can also be established:

\begin{equation}
\sum q_i a_i \triangleq A \geqslant G \triangleq a_1^{q_1} \cdots a_n^{q_n} \tag{$1^{\prime}$}
\end{equation}
where $q_i > 0$ \& $\sum q_i = 1$. 


\section{Bernoulli inequality}

\begin{Th} \label{th2} 

  \textnormal{For} $x \in (-1, \infty)$: 

  \begin{equation}
    (1+x)^{\alpha}  \begin{array}{c}
      \leqslant \\ 
      = \\ 
      \geqslant  
    \end{array}
    (1+\alpha x), \textnormal{when}~\alpha 
    \begin{array}{l}
    \in (0,1) \\  
    = 0, 1 \\
    \notin(0, 1)     
    \end{array}
  \end{equation}
  
  \end{Th}
  
\begin{proof} The Talyor expantion (second order) of function $f(x) = (1+x)^{\alpha}$ at $x_0 = 0$ with Lagrange remainder: 
  \begin{equation}\label{eq:star2}
(1+x)^{\alpha} = (1+0)^{\alpha} + \frac{\alpha(1+0)^{\alpha-1}}{r!}\cdot x + \frac{\alpha(\alpha-1)\cdot(1+\xi)^{\alpha-2}}{2!}\cdot x^2 \tag{*2}    
  \end{equation}  
  where $x>-1$, but $\xi$ is between 0 and $x$, so there is always $1+\xi > 0$, from \eqref{eq:star2} one get \eqref{th2} immediately.  
\end{proof}

Note: 
\begin{enumerate}

  \item [$1^{\circ}$] Let $1+x=t > 0$. \eqref{th2} can be written as:  
  
  \begin{equation}\label{eq:2p}
    t^{\alpha}  \begin{array}{c}
      \leqslant \\ 
      = \\ 
      \geqslant  
    \end{array}
    (1+\alpha x), \textnormal{when}~\alpha 
    \begin{array}{l}
    \in (0,1) \\  
    = 0, 1 \\
    \notin(0, 1)     
    \end{array}
    \tag{$2^{\prime}$}
  \end{equation}


  \item [$2^{\circ}$] The \eqref{th2} can also be proved by elementary mathematics~\cite{shi1964}. 

  \item [$3^{\circ}$] From the functional images on both sides of the inequality, we can call it an inequality with straight boundaries. Because of this, its usefulness is vast and it plays an important role in the inequality family.

\end{enumerate}



\section{H\"older inequality}

\begin{Th} \label{th3} 
  For any real number $r$, has: 
 
  \begin{equation}
    \sum^n_{i=1} a_i^r\cdot b_i^{1-r} 
      \begin{array}{c}
        \leqslant \\ 
        \geqslant  
      \end{array}
    \left (\sum_{i=1}^n a_i \right)^r  
    \left (\sum_{i=1}^n b_i \right)^{1-r}, \textnormal{when} 
    \begin{array}{l}
    \in (0,1) \\  
    \notin(0, 1)     
    \end{array}
    (0, 1)
  \end{equation}

\end{Th}

\begin{proof}
Let $\theta_i\triangleq a_i/\sum_{j=1}^n a_j$, $\delta_i\triangleq b_i/\sum_{j=1}^n b_j$, then \eqref{th3} is equal with 
\begin{equation}\label{eq:star3}
  \sum^n_{i=1} \theta_i^r\cdot \delta_i^{1-r} 
      \begin{array}{c}
        \leqslant \\ 
        \geqslant  
      \end{array} 
    1, \textnormal{when} 
    \begin{array}{l}
    \in (0,1) \\  
    \notin(0, 1)     
    \end{array}
    (0, 1) \tag{*3}
\end{equation}

Note, the left side of \eqref{eq:star3} can be written as 

$$\sum_{i=1}^n \left( \frac{\theta_i}{\delta_i} \right)^r \cdot \delta_i $$ 

for which $\left( \frac{\theta_i}{\delta_i} \right)^r$ use \eqref{eq:2p} (where $\sum\delta_i = 1 = \sum\theta_i$) will get \eqref{eq:star3}. 
\end{proof}

Note: 
\begin{enumerate}

  \item [$1^{\circ}$] \eqref{th3} can be simply written as: 
  \begin{equation}\label{eq:3p}
    | \mathbb{a}^r \cdot \mathbb{b}^{1-r} | 
    \begin{array}{c}
      \leqslant \\ 
      \geqslant  
    \end{array}
    | \mathbb{a}|^r \cdot |\mathbb{b}|^{1-r}, \textnormal{when} r
    \begin{array}{l}
    \in \\  
    \notin     
    \end{array}
    (0, 1) \tag{$3^{\prime}$} 
  \end{equation}
  
  \item [$2^{\circ}$] Compare with \eqref{eq:3p} easy get: 

  \begin{equation}\label{eq:4}
    \begin{split}
      | \mathbb{a}^p \cdot \mathbb{b}^q | = | \mathbb{a}^{p\cdot\frac{1}{r}\cdot r} \cdot \mathbb{b}^{q\cdot\frac{1}{(1-r)}\cdot(1-r)}| 
      \begin{array}{c}
        \leqslant \\ 
        \geqslant  
      \end{array}
      | \mathbb{a}^{p\cdot\frac{1}{r}}|^r \cdot |\mathbb{b}^{q\cdot\frac{1}{(1-r)}}|^{1-r}\triangleq \\ \triangleq  
      |\mathbb{a}^{p\cdot k}|^{\frac{1}{k}} \cdot |\mathbb{b}^{q\cdot k^{\prime}}|^{\frac{1}{k^{\prime}}} = |\mathbb{a}^p|_k \cdot |\mathbb{b}^q|_{k^{\prime}}, \textnormal{when}~k
      \begin{array}{l}
        >  \\  
        <      
      \end{array}
      1.
    \end{split}
  \end{equation}
  where $\frac{1}{r}=k$, $\frac{1}{(1-r)}=k^{\prime}$, but $\frac{1}{k}+\frac{1}{k^{\prime}}=1$. Called $k$ and $k'$ conjugate. 

Also, $r \begin{array}{c} \in \\ \notin \end{array} (0,1)$ equivalent to $k \begin{array}{c} > \\ < \end{array} 1$. 
  
Specifically, when $p=q=1$, \eqref{eq:4} becomes 

\begin{equation}\label{eq:4p}
  | \mathbb{a}\cdot\mathbb{b}|\begin{array}{c}
  \leqslant \\ 
  \geqslant    
  \end{array}
  |\mathbb{a}|_k \cdot | \mathbb{b}|_{k'}, \textnormal{when}~k
  \begin{array}{l}
    >  \\  
    <      
  \end{array}
  1.  \tag{$4'$} 
\end{equation}
Also, when $p=1$, $q=r-1$, take $k=r$, get $(k'=\frac{r}{r-1})$ 

\begin{equation}\label{eq:4pp}
  | \mathbb{a}\cdot\mathbb{b}^{r-1}|\begin{array}{c}
  \leqslant \\ 
  \geqslant    
  \end{array}
  |\mathbb{a}|_r \cdot | \mathbb{b}|_r^{r-1}, \textnormal{when}~r
  \begin{array}{l}
    >  \\  
    <      
  \end{array}
  1.  \tag{$4''$} 
\end{equation}

\item [$3^{\circ}$] \eqref{eq:4p} is common form of bidirectional H\"older inequality. For simplicity, we call \eqref{th3}, \eqref{eq:4}, \eqref{eq:4pp} as (binary) first, second, and $r^{th}$ bidirectional H\"older inequality.  

\item [$4^{\circ}$] The first part of \eqref{th3} can be proved by $A\geqslant G$, also $A\geqslant G$ can proof multivariate one-way H\"older inequality:
\begin{equation}\label{eq:5}
  \sum_{i=1}^n a_i^{\alpha}\cdot b_i^{\beta}\cdot \cdots \cdot l_i^{\lambda} \leqslant\left(\sum a_i\right)^{\alpha} \cdot \left(\sum b_i\right)^{\beta}\cdot \cdots \cdot \left(\sum l_i\right)^{\lambda}
\end{equation}
where $\alpha, \beta, \cdots, \lambda$ are all positive and $\alpha + \beta + \cdots + \lambda = 1$. 

\item [$5^{\circ}$] Because $|\mathbb{a}|_{k'} \left\{ \begin{array}{c}
  \overrightarrow{k\to 1+0} \max a_i \\ 
  \overrightarrow{k\to 1-0} \min a_i \end{array}\right.  \textnormal{(see Theorem 7)}$

  Let 
  $$ A \triangleq \max \left\{ [ |\mathbb{a}|_k\cdot |\mathbb{b}|_{k'}: k < 1 ]\cup[|\mathbb{a}|_{k'}\cdot |\mathbb{b}|_k]: k<1]\cup[|\mathbb{a}|\cdot \min b_i, |\mathbb{b}|\min a_i]\right\}$$ 

  $$ B \triangleq \min \left\{ [ |\mathbb{a}|_k\cdot |\mathbb{b}|_{k'}: k > 1 ]\cup[|\mathbb{a}|_{k'}\cdot |\mathbb{b}|_k]: k>1]\cup[|\mathbb{a}|\cdot \max b_i, |\mathbb{b}|\max a_i]\right\}$$ 
  then because of \eqref{eq:4p} has $A\leqslant |\mathbb{a b}| \leqslant B$. 

  \item [$6^{\circ}$] H\"older inequality defines the sum of products (in particular, the product sum of many pairs of numbers). This kind of ubiquity in mathematics (such as definite integral) determines its unique position in the family of inequalities.

\end{enumerate}


\section{Modulo mean power function}

In order to use analytical methods to deal with some of the problems in modular and exponential averaging, introduce the function of $r$ (non-zero real number): 

$$\Phi(r;\mathbb{a}, \mathbb{c}) = \left( \sum_{i=1}^n c_i a_i^r \right)^{\frac{1}{r}} = |\mathbb{c}\cdot \mathbb{a}^r|^{\frac{1}{r}}$$ 

where $a_i$, $c_i$ are all positive numbers. Because when $c_i \equiv 1$ which is the $r$-module of $|\mathbb{a}|_r$; while when $c_i >0 \& \sum_{i=1}^n c_i = 1$, which is the $r$-order power average. The $M(r; \mathbb{a},\mathbb{c})$ is called modulus mean power function. Regarding the situation that it changes due to the increment of $r$, we have

\begin{Th} \label{th4}
  \textnormal{When} $r \nearrow$ \textnormal{then}
  \begin{equation} 
    \Phi(r;\mathbb{a},\mathbb{c}) \left\{ \begin{array}{cl}
    \searrow & \textnormal{when}~ c_i \geqslant 1~ \textnormal{especially}~c_i=1~(i=1,\cdots,n);  \\
    \nearrow & \textnormal{when}~ \sum_i^n c_i \leqslant 1~ \textnormal{especially}\sum c_i=1.      
    \end{array} \right.
  \end{equation}  
  
\end{Th}

\begin{proof}
  From $$\Phi=e^{\ln\Phi}=e^{\frac{1}{r}\ln\sum c_i a_i^r} \triangleq e^{\phi(r)}$$ knows $\Phi_r'$ has the same sign with $\phi_r'$. However
\begin{equation*}
\begin{split}
  \phi' & = \frac{-1}{r^2}\ln\sum_i c_i a_i^r + \frac{1}{r}\cdot\frac{\sum_i c_i a_i^r\ln a_i}{\sum_j c_j a_j^r} \\
        & = \frac{1}{r^2} \left[\sum_i  \left(\frac{c_i a_i^r}{\sum_j c_j a_j^r}\right)\cdot \ln a_i^r-\ln\sum_i c_i a_i^r \right] \\ 
        & = \frac{1}{r^2} \left[\ln \prod_{i=1}^n \left(a_i^r\right)^{\theta_i} - \ln\sum_i c_i a_i^r \right] \\
        & = \frac{1}{r^2} \ln\prod_{i=1}^n \left(\frac{\theta_i}{c_i}\right)^{\theta_i}, 
\end{split}
\end{equation*}
where $\theta_i\triangleq c_i a_i^r / \sum\limits_{j=1}^n c_j a_j^r, \sum\limits_i^n \theta_i = 1$. Whether $\phi'(r)$ is positive or negative depends on whether $\prod\limits_{i=1}^n\left(\frac{\theta_i}{c_i} \right)^{\theta_i}$ is greater than 1 or not. 

Obviously, 

\begin{enumerate}

  \item [$1^{\circ}$] when $c_i\geqslant 1 (i=1,\cdots , n)$, $\prod\limits_{i=1}^n (\theta_i/c_i)^{\theta_i}<1$. So $\phi'(r)$ and $\Phi'(r)$ are all less than 0, thus $\Phi(r) \searrow$. Especially when $c_i\equiv1$ as Jensen inequality called. 

\end{enumerate}

\end{proof}

\begin{thebibliography}{99} 

\bibitem{shi1964} Jihuai Shi, \textit{Average}, 1964, People's education press.  


\end{thebibliography}



\end{document}